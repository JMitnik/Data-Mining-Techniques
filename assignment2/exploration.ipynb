{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Setting up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, RFE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config parameters:\n",
    "\n",
    "nrows: default dataframelength: 4958347\n",
    "\n",
    "classifiers: (SVC, linearSVC, RidgeClassifier)\n",
    "    - SVC params: C (0-1), kernel (rbf, linear, poly), max_iter (-1, int), random_state (int)\n",
    "    - linearSVC params: C (0-1), penalty (l1, l2), max_iter (1000, int), random_state (int) \n",
    "    - RidgeClassifier params: max_iter (1000, int), random_state (int) \n",
    "    \n",
    "feature_selection: (SelectFromModel, SelectKBest, RFE)\n",
    "    - SelectFromModel params: threshold (0-int), max_features (0-int)\n",
    "    - SelectKBest params: threshold (0-int), k (0-int)\n",
    "    - RFE params: n_features_to_select (0-int), step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import Config\n",
    "\n",
    "# Config Settings\n",
    "config = Config(\n",
    "    nrows=None,\n",
    "    pre_feature_selection=False, #todo Bug in prefeature selection = False\n",
    "    train_data_subset=0.8,\n",
    "    classifier=SVC,\n",
    "    classifier_dict={'C' : 1, 'kernel' : 'rbf', 'random_state' : 2},\n",
    "    feature_selection=SelectFromModel,\n",
    "    feature_selection_dict={'threshold' : 1},\n",
    "    dimensionality_reduc=True,\n",
    "    dimension_features=25,\n",
    "    feature_engineering=True,  \n",
    "    naive_imputing=False #todo faster method for averaging nan values if naive=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config.nrows is not None:\n",
    "    train_data = pd.read_csv('data/training_set_VU_DM.csv', nrows=config.nrows)\n",
    "else:\n",
    "    train_data = pd.read_csv('data/training_set_VU_DM.csv')\n",
    "original_columns = train_data.columns\n",
    "train_data.head(5) # Show top 5\n",
    "train_data_nans = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Column exploration\n",
    "---\n",
    "## Main columns\n",
    "- `search_id` seems to represent each individual 'user'.\n",
    "- `booking_bool` is essentially the answer.\n",
    "\n",
    "## Categorical features\n",
    "The following features are categorical (to be onehot-encoded):\n",
    "\n",
    "User-specific\n",
    "- `site_id`: category of website Expedia used\n",
    "- `visitor_location_country_id`: categories of which country user is from\n",
    "- `srch_destination_id`: where did the user search from\n",
    "- `srch_saturday_night_bool`: boolean if stay includes staturday\n",
    "\n",
    "Hotel-specific:\n",
    "- `prop_id`: categories of associated hotels\n",
    "- `prop_brand_bool`: boolean if hotel is part of chain or not\n",
    "- `promotion_flag`: displaying promotion or not\n",
    "\n",
    "Expedia-specific vs competitors 1_8:\n",
    "- `comp{i}_rate`: if expedia has a lower price, do +1, 0 if same, -1 price is higher, null if no competitive data\n",
    "- `comp{i}_inv`: if competitor has no availability, +1, 0 if both have availability, null if no competitive data\n",
    "\n",
    "## Numerical features\n",
    "\n",
    "User-specific\n",
    "- `visitor_hist_starrating`: average of previous stars of associated user\n",
    "- `visitor_hist_adr_usd`: average price per night of hotels of associated user\n",
    "- `srch_length_of_stay`: number of nights stays **searched** \n",
    "- `srch_booking_window`: number of days ahead the start of booking window **searched**\n",
    "- `srch_adults_count`: number of adults **searched**\n",
    "- `srch_children_count`: number of children **searched**\n",
    "- `srch_room_count`: number of rooms **searched**\n",
    "- `random_bool`: if sort was random at time of search\n",
    "- `gross_booking_usd`: ❗Training-only❗ payment includign taxes, etc for hotel\n",
    "\n",
    "Hotel-specific\n",
    "- `prop_starrating`: star rating of hotel (1-5)\n",
    "- `prop_review_score`: average review score of hotel (1-5)\n",
    "- `prop_location_score_1`: score1 of hotel's location desirability\n",
    "- `prop_location_score_2`: score2 of hotel's location desirability\n",
    "- `prop_log_historical_price`: logarithm of average price of hotel lately (0 == not sold)\n",
    "- `price_usd`: displayed price of hotel.\n",
    "    - ❗ Important: Different countries have different conventions.\n",
    "    - Value can change per night\n",
    "- `srch_query_affinity_score`: log probability a hotel is clicked in internet searches\n",
    "\n",
    "User-hotel coupled:\n",
    "- `orig_destination_distance`: distance between hotel and customer at search-time (null means no distance calculated)\n",
    "\n",
    "Expedia-specific vs competitors 1_8:\n",
    "- `comp{i}_rate_percent_diff`: absolute difference between expedia and competitor's price, with null being no competitive data\n",
    "\n",
    "\n",
    "## Unknown type\n",
    "- `date_time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.feature_engineering:\n",
    "\n",
    "    time = pd.to_datetime(train_data['date_time'])\n",
    "    train_data['month']=time.dt.month\n",
    "    train_data['year']=time.dt.year\n",
    "    train_data['same_country_visitor_prop']=np.where(train_data['visitor_location_country_id'] == train_data['prop_country_id'],1,0)\n",
    "    train_data['viable_comp']= np.where(\n",
    "                      (train_data['comp1_rate']== -1)& (train_data['comp1_inv']== 0) |\n",
    "                      (train_data['comp2_rate']== -1)& (train_data['comp2_inv']== 0) |\n",
    "                      (train_data['comp3_rate']== -1)& (train_data['comp3_inv']== 0) |\n",
    "                      (train_data['comp4_rate']== -1)& (train_data['comp4_inv']== 0) |\n",
    "                      (train_data['comp5_rate']== -1)& (train_data['comp5_inv']== 0) |\n",
    "                      (train_data['comp6_rate']== -1)& (train_data['comp6_inv']== 0) |\n",
    "                      (train_data['comp7_rate']== -1)& (train_data['comp7_inv']== 0) |\n",
    "                      (train_data['comp8_rate']== -1)& (train_data['comp8_inv']== 0) \n",
    "                      ,1,0)\n",
    "\n",
    "    mcol=train_data.loc[:,['prop_location_score1', 'prop_location_score2']]\n",
    "    train_data['prop_mean_score'] = mcol.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we engineer new features, we might want to remove their old columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.feature_engineering:\n",
    "    train_data = train_data.drop(columns=['date_time', 'visitor_location_country_id', 'prop_country_id', \n",
    "                             'prop_location_score1', 'prop_location_score2'])\n",
    "    for i in range(8):\n",
    "        train_data = train_data.drop(columns=['comp' + str(i+1) + '_rate'])\n",
    "        train_data = train_data.drop(columns=['comp' + str(i+1) + '_inv'])\n",
    "        train_data = train_data.drop(columns=['comp' + str(i+1) + '_rate_percent_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'site_id', 'visitor_hist_starrating', 'visitor_hist_adr_usd',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance', 'random_bool', 'click_bool',\n",
       "       'gross_bookings_usd', 'booking_bool', 'month', 'year',\n",
       "       'same_country_visitor_prop', 'viable_comp', 'prop_mean_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup: Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_review_score',\n",
       "       'srch_query_affinity_score', 'orig_destination_distance',\n",
       "       'gross_bookings_usd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will have to cleanup our data next up. Let's first impute the missing columns. \n",
    "# To do this we search for the columns with nans\n",
    "na_cols = train_data.isna().any()\n",
    "nan_cols = train_data.columns[na_cols]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from `comp{i}_rate` and `comp2_inv`, all of these columns are numerical features. We could, initially,\n",
    "simply replace all these values with -1 for the moment.\n",
    "\n",
    "❗ Important: Note, this is actually incorrect, but might work for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple numerical impute: select numerical data, fill it with -1\n",
    "if config.naive_imputing:    \n",
    "    imputed_numerical_data = train_data[nan_cols].filter(regex='[^comp\\d_(rate|inv)$]')\n",
    "    imputed_numerical_data = imputed_numerical_data.fillna(-1)\n",
    "    train_data.update(imputed_numerical_data)\n",
    "\n",
    "    # Manual cleanup to ensure no problem with space\n",
    "    del imputed_numerical_data\n",
    "    train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simple naive categorical impute\n",
    "if config.naive_imputing:    \n",
    "    na_cols = train_data.columns[train_data.isna().any()]\n",
    "    imputed_categorical_data = train_data[na_cols].fillna(-2)\n",
    "    train_data.update(imputed_categorical_data)\n",
    "\n",
    "    # Cleanup\n",
    "    del imputed_categorical_data\n",
    "    train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second, less naive approach is to average numerical values grouped by either their hotel (prop_id) or the user (srch_id).\n",
    "On top of that we would want to remove columns with over 50% null Values (refence for this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id                        0.000000\n",
       "date_time                      0.000000\n",
       "site_id                        0.000000\n",
       "visitor_location_country_id    0.000000\n",
       "prop_country_id                0.000000\n",
       "prop_id                        0.000000\n",
       "prop_starrating                0.000000\n",
       "prop_review_score              0.001485\n",
       "prop_brand_bool                0.000000\n",
       "prop_location_score1           0.000000\n",
       "prop_location_score2           0.219902\n",
       "prop_log_historical_price      0.000000\n",
       "position                       0.000000\n",
       "price_usd                      0.000000\n",
       "promotion_flag                 0.000000\n",
       "srch_destination_id            0.000000\n",
       "srch_length_of_stay            0.000000\n",
       "srch_booking_window            0.000000\n",
       "srch_adults_count              0.000000\n",
       "srch_children_count            0.000000\n",
       "srch_room_count                0.000000\n",
       "srch_saturday_night_bool       0.000000\n",
       "orig_destination_distance      0.324258\n",
       "random_bool                    0.000000\n",
       "click_bool                     0.000000\n",
       "booking_bool                   0.000000\n",
       "month                          0.000000\n",
       "year                           0.000000\n",
       "same_country_visitor_prop      0.000000\n",
       "viable_comp                    0.000000\n",
       "prop_mean_score                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove columns with over 50% nans\n",
    "if config.naive_imputing == False:\n",
    "\n",
    "    for column in train_data_nans.columns:\n",
    "        if train_data_nans[column].isnull().sum()/len(train_data_nans) > 0.5:\n",
    "            train_data_nans = train_data_nans.drop(columns=column, axis=1)\n",
    "\n",
    "train_data_nans.isnull().sum()/len(train_data_nans)\n",
    "    #remove data with > 0.50 nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slow method of averaging mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop_review_score\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2013-02-06 19:51:542013-06-13 08:56:152012-11-17 08:14:072013-04-08 07:44:362013-05-08 05:59:382013-03-06 20:12:102012-12-16 08:39:372013-04-29 12:07:192013-05-25 21:37:472013-06-06 15:06:482012-12-27 09:22:592013-04-09 12:59:342013-03-29 01:00:202013-02-21 07:21:142013-06-18 06:48:442013-05-01 15:13:452012-12-02 12:01:162013-01-17 14:31:542013-05-26 11:24:132013-04-24 15:44:592012-11-30 11:01:442013-03-04 08:59:092013-03-21 12:27:372013-01-27 14:38:202013-02-13 18:28:242013-05-28 08:23:172013-03-18 19:10:382013-04-28 20:41:462013-04-10 10:19:192013-04-10 06:44:302013-02-06 06:11:012013-06-12 15:37:292013-06-10 14:49:022013-04-29 16:07:422013-06-04 19:47:292013-06-22 16:44:352013-02-25 20:32:592012-11-06 08:58:262012-11-09 12:49:162013-01-31 11:03:162013-05-29 21:09:242013-02-10 11:19:142013-01-16 11:57:282012-11-26 21:21:372013-06-18 16:30:392013-06-25 16:45:582013-04-04 18:39:502013-05-11 14:51:372012-12-05 19:21:592013-05-12 20:47:342013-01-14 13:42:172012-11-08 04:09:332013-04-26 10:16:532013-05-25 10:28:112012-11-04 07:03:312013-04-18 07:34:242013-05-08 11:09:142013-03-19 18:02:592013-06-09 20:22:162013-02-25 08:56:482012-12-05 13:46:23'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_transform_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1369\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_choose_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_choose_path\u001b[1;34m(self, fast_path, slow_path, group)\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m   1475\u001b[0m             slow_path = lambda group: group.apply(\n\u001b[1;32m-> 1476\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1475\u001b[0m             slow_path = lambda group: group.apply(\n\u001b[1;32m-> 1476\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m             )\n",
      "\u001b[1;32m<ipython-input-15-672c520e57cc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     19\u001b[0m                           ]:\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prop_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11214\u001b[0m         return self._reduce(\n\u001b[1;32m> 11215\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11216\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3890\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3891\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1309\u001b[0m                 \u001b[1;31m# e.g. \"foo\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not convert {x} to numeric\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 2013-02-06 19:51:542013-06-13 08:56:152012-11-17 08:14:072013-04-08 07:44:362013-05-08 05:59:382013-03-06 20:12:102012-12-16 08:39:372013-04-29 12:07:192013-05-25 21:37:472013-06-06 15:06:482012-12-27 09:22:592013-04-09 12:59:342013-03-29 01:00:202013-02-21 07:21:142013-06-18 06:48:442013-05-01 15:13:452012-12-02 12:01:162013-01-17 14:31:542013-05-26 11:24:132013-04-24 15:44:592012-11-30 11:01:442013-03-04 08:59:092013-03-21 12:27:372013-01-27 14:38:202013-02-13 18:28:242013-05-28 08:23:172013-03-18 19:10:382013-04-28 20:41:462013-04-10 10:19:192013-04-10 06:44:302013-02-06 06:11:012013-06-12 15:37:292013-06-10 14:49:022013-04-29 16:07:422013-06-04 19:47:292013-06-22 16:44:352013-02-25 20:32:592012-11-06 08:58:262012-11-09 12:49:162013-01-31 11:03:162013-05-29 21:09:242013-02-10 11:19:142013-01-16 11:57:282012-11-26 21:21:372013-06-18 16:30:392013-06-25 16:45:582013-04-04 18:39:502013-05-11 14:51:372012-12-05 19:21:592013-05-12 20:47:342013-01-14 13:42:172012-11-08 04:09:332013-04-26 10:16:532013-05-25 10:28:112012-11-04 07:03:312013-04-18 07:34:242013-05-08 11:09:142013-03-19 18:02:592013-06-09 20:22:162013-02-25 08:56:482012-12-05 13:46:23 to numeric",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-672c520e57cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                            \u001b[1;34m'srch_query_affinity_score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                           ]:\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prop_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_kernel_whitelist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_transform_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1370\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_choose_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_item_by_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"transform must return a scalar value for each group\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_transform_item_by_item\u001b[1;34m(self, obj, wrapper)\u001b[0m\n\u001b[0;32m   1511\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1513\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1514\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m                 \u001b[1;31m# e.g. trying to call nanmean with string values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_kernel_whitelist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_transform_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m   1472\u001b[0m             )\n\u001b[0;32m   1473\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m             \u001b[0mfast_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1475\u001b[0m             slow_path = lambda group: group.apply(\n\u001b[0;32m   1476\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-672c520e57cc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m                            \u001b[1;34m'srch_query_affinity_score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                           ]:\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prop_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_nans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   4157\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4158\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4159\u001b[1;33m             \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4160\u001b[0m         )\n\u001b[0;32m   4161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   6214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6215\u001b[0m                 new_data = self._data.fillna(\n\u001b[1;32m-> 6216\u001b[1;33m                     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6217\u001b[0m                 )\n\u001b[0;32m   6218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fillna\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mfillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if config.naive_imputing == False:\n",
    "\n",
    "    #fill in nans with mean values:\n",
    "    na_cols = train_data_nans.isna().any()\n",
    "    nan_cols = train_data_nans.columns[na_cols]\n",
    "    for column in nan_cols:\n",
    "        print (column)\n",
    "        if column in ['visitor_hist_starrating', 'visitor_hist_adr_usd',  \n",
    "                         'srch_length_of_stay', 'srch_booking_window', \n",
    "                         'srch_adults_count', 'srch_children_count',\n",
    "                         'srch_room_count'                      \n",
    "                        ]:\n",
    "            train_data_nans[column] = train_data_nans.groupby('srch_id').transform(lambda x: x.fillna(x.mean()))\n",
    "        elif column in ['prop_starrating', 'prop_review_score', \n",
    "                           'prop_location_score1', 'prop_location_score2', \n",
    "                           'prop_log_historical_price', 'price_usd',\n",
    "                           'search_', 'orig_destination_distance',  \n",
    "                           'srch_query_affinity_score'\n",
    "                          ]:\n",
    "            train_data_nans[column] = train_data_nans.groupby('prop_id').transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    train_data_nans.isnull().sum()/len(train_data_nans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for feature transformation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we definehow we would like to encode\n",
    "\n",
    "# For One-Hot Encoding\n",
    "# Onehot encode the categorical variables\n",
    "oh_columns = ['site_id', 'visitor_location_country_id', 'prop_country_id', \n",
    "              'prop_id', 'prop_brand_bool', 'promotion_flag', \n",
    "              'srch_destination_id', 'srch_saturday_night_bool', 'random_bool'\n",
    "             ]\n",
    "oh_impute = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-2)\n",
    "oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "oh_pipeline = Pipeline([\n",
    "    ('impute', oh_impute),\n",
    "    ('encode', oh_encoder)\n",
    "])\n",
    "# TODO: competitor columns\n",
    "for column in oh_columns:\n",
    "    train_data[column]=train_data[column].astype('category')\n",
    "\n",
    "\n",
    "# Encode the numerical values\n",
    "num_scale_columns = ['visitor_hist_starrating', 'visitor_hist_adr_usd', \n",
    "                     'prop_starrating', 'prop_review_score', \n",
    "                     'prop_location_score1', 'prop_location_score2', \n",
    "                     'prop_log_historical_price', 'price_usd', \n",
    "                     'srch_length_of_stay', 'srch_booking_window', \n",
    "                     'srch_adults_count', 'srch_children_count',\n",
    "                     'srch_room_count', 'srch_query_affinity_score', \n",
    "                     'orig_destination_distance' \n",
    "                    ]\n",
    "num_impute = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "num_scale_encoder = StandardScaler()\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', num_impute),\n",
    "    ('encode', num_scale_encoder)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual feature-selection\n",
    "# We do a preselection of columns that we feel will become useful features after encoding\n",
    "if config.pre_feature_selection == True:\n",
    "    chosen_columns = ['prop_starrating', 'prop_review_score', 'prop_location_score1', 'prop_location_score2', \n",
    "                      'prop_log_historical_price', 'price_usd', 'srch_query_affinity_score',  'promotion_flag']\n",
    "else:\n",
    "    chosen_columns = oh_columns + num_scale_columns\n",
    "\n",
    "# Select the chosen columns, and \n",
    "# define the corresponding transformer's transformations to their columns\n",
    "chosen_oh_cols = list(set(chosen_columns) & set(oh_columns))\n",
    "chosen_num_cols = list(set(chosen_columns) & set(num_scale_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (chosen_columns)\n",
    "chosen_train_data = train_data[chosen_columns]\n",
    "\n",
    "df_transformer = ColumnTransformer([\n",
    "    ('oh', oh_pipeline, chosen_oh_cols),\n",
    "    ('num', num_pipeline, chosen_num_cols),\n",
    "], remainder='drop')\n",
    "\n",
    "# We fit this transformer on our training data, and transform/encode our training data\n",
    "encoded_X = df_transformer.fit_transform(chosen_train_data)\n",
    "\n",
    "# We also represent this same X using the original columns.\n",
    "new_oh_columns = df_transformer.named_transformers_.oh.named_steps.encode.get_feature_names(chosen_oh_cols)\n",
    "encoded_columns = [ *new_oh_columns, *chosen_num_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the y-target in general\n",
    "X_only = train_data.copy()\n",
    "y = X_only.pop('booking_bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### We apply feature selection using the model from our config\n",
    "if config.PCA_use:\n",
    "    pca = TruncatedSVD(n_components=config.PCA_features)\n",
    "    feature_encoded_X = pca.fit_transform(encoded_X)\n",
    "else:\n",
    "    classifier = config.classifier(**config.classifier_dict)\n",
    "    feature_selector = config.feature_selection(classifier, **config.feature_selection_dict)\n",
    "    feature_encoded_X = feature_selector.fit_transform(encoded_X, y)\n",
    "    # TODO: support_ method might not work on every featureselector we choose, test this\n",
    "    bool_vec = feature_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Utility cell to investigate data elements\n",
    "# Data elements we have available\n",
    "# Encoded data:\n",
    "    # - df_encoded_X: Dataframe that contains the preprocessed features\n",
    "    # - encoded_X: numpy version of `encoded_df`\n",
    "# Original data:\n",
    "    # - train_data: training data, but cleaned up\n",
    "    # - X_only: `train_data` without `booking_bool`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try a various amount of models with parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# Gets the sizes of same search-id chunks.\n",
    "get_user_groups_from_df = lambda df: df.groupby('srch_id').size().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign `srch_id`\n",
    "# feature_encoded_X['srch_id'] = train_data['srch_id'].astype(int)\n",
    "srch_id_col = train_data['srch_id'].astype(int)\n",
    "srch_id_col = np.array(srch_id_col)\n",
    "# srch_id_col = srch_id_col.reshape(-1,1)\n",
    "# print (srch_id_col.shape)\n",
    "# print(feature_encoded_X.shape)\n",
    "\n",
    "# feature_encoded_X_2 = np.vstack((feature_encoded_X, srch_id_col))\n",
    "# print (feature_encoded_X_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn-to-rank with LGBMRanker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we decide to split our data into train/val, we can do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# feature_encoded_X = encoded_X\n",
    "# Split data into 80% train and 20% validation, maintaining the groups however.\n",
    "train_inds, val_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7).split(feature_encoded_X, groups=srch_id_col))\n",
    "\n",
    "# Split train / validation by their indices\n",
    "df_X_train = feature_encoded_X[train_inds]\n",
    "y_train = y[train_inds]\n",
    "df_X_val = feature_encoded_X[val_inds]\n",
    "y_val = y[val_inds]\n",
    "\n",
    "# Get the groups related to `srch_id`\n",
    "query_train = get_user_groups_from_df(train_data.iloc[train_inds])\n",
    "query_val = get_user_groups_from_df(train_data.iloc[val_inds])\n",
    "\n",
    "# Remove srch_id\n",
    "# df_X_train.pop('srch_id')\n",
    "# df_X_val.pop('srch_id')\n",
    "print(\"Ready to rank!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our ranker (default parameters)\n",
    "gbm = lgb.LGBMRanker(n_estimators=200)\n",
    "\n",
    "gbm.fit(df_X_train, y_train, group=query_train,\n",
    "        eval_set=[(df_X_val, y_val)], eval_group=[query_val],\n",
    "        eval_at=[5, 10, 20], early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import os\n",
    "def ensure_path(path_to_file):\n",
    "    os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
    "\n",
    "ensure_path('storage/best_gbm.txt')\n",
    "gbm.booster_.save_model('storage/best_gbm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data, encoded_X, feature_encoded_X, X_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from guppy import hpy\n",
    "gc.collect()\n",
    "h=hpy()\n",
    "h.heap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with LGBM-Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read test data, and use the same columns as was used for training\n",
    "df_test_data = pd.read_csv('data/test_set_VU_DM.csv')\n",
    "chosen_test_data = df_test_data[chosen_columns]\n",
    "\n",
    "# Apply transformations (encoding + selection)\n",
    "encoded_test_data = df_transformer.transform(chosen_test_data)\n",
    "\n",
    "if config.PCA_use:\n",
    "    filtered_test_data = pca.transform(encoded_test_data)\n",
    "else:\n",
    "    filtered_test_data = encoded_test_data[:, bool_vec]\n",
    "                                    \n",
    "X_test = filtered_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on a per-group basis: slow as hell (skip section for faster method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split test-data into groups based on the original data\n",
    "# groups = df_test_data.groupby('srch_id').indices\n",
    "# groups_by_idxs = list(groups.values())\n",
    "# print (groups_by_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "def predict_for_group(X_test, group_idxs, df_test_data):\n",
    "    # Use gbm to predict\n",
    "    X_test_group = X_test[group_idxs]\n",
    "    preds = gbm.predict(X_test_group)\n",
    "    preds = preds.argsort()[::-1] # Reverses\n",
    "    \n",
    "    # Get th\n",
    "    pred_idxs = group_idxs[preds]\n",
    "    pred_props = df_test_data.loc[pred_idxs, ['srch_id', 'prop_id']]\n",
    "    \n",
    "    return pred_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Doing it on a 'per-group basis'\n",
    "# Commented because it is slow.\n",
    "# # Perform the prediction (Can take a while, shitton of predictions)\n",
    "# result = []\n",
    "\n",
    "# for i, idx_group in enumerate(groups_by_idxs):\n",
    "#     preds = predict_for_group(X_test, idx_group, df_test_data)\n",
    "#     result.append(preds)\n",
    "    \n",
    "#     if i % 10000 == 0:\n",
    "#         print(f\"Doing group {i + 1} / {len(groups_by_idxs)} now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting all at once: More performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = gbm.predict(X_test)\n",
    "df_test_data['pred'] = pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort predictions based on srch_id and pred\n",
    "sorted_preds = df_test_data[['srch_id', 'prop_id', 'pred']].sort_values(by=['srch_id', 'pred'], ascending=[True, False]).reset_index()\n",
    "\n",
    "# Save\n",
    "sorted_preds[['srch_id', 'prop_id']].to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('results.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
